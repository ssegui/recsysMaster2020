{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated February 2020 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Non-Personalized recommeder systems</h3><br></div>\n",
    "\n",
    "<br>\n",
    "<p>A non-personalized recommender system is one that makes the same recommendations for everyone. </p>\n",
    "\n",
    "The simplest example is a retailer that shows the ten (or some number) most popular products on their homepage. <br>\n",
    "Some examples: <br><br>\n",
    "IMDB: MOVIE RANKING\n",
    "![alt IMDB](images/np1.png)\n",
    "\n",
    "___\n",
    "Amazon: Top Recommendations\n",
    "![alt Amazon](images/np2.png)\n",
    "___\n",
    "Amazon: Product Association\n",
    "![alt Amazon](images/np3.png)\n",
    "___\n",
    "Reedit: News Recommendations\n",
    "![alt Reedit](images/np4.png)\n",
    "\n",
    "\n",
    "<p><b>Several</b> cases but <b>two main</b> approaches\n",
    "\n",
    "1. Aggregated opinion recommenders\n",
    "2. Basic product association recommenders\n",
    "<br>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Aggregated opinion recommenders</h3><br></div>\n",
    "\n",
    "Usually, the problem posed as a learning to rank problem. But what seems to be straighfowrard becomes a really complicated question: <b>How do you rank your rated items and which logic to use to display them?</b>\n",
    "\n",
    "In order to score/rank items we first have to <b>understand the business case</b>. Of course, several factors plays a role. For instance, \n",
    "\n",
    "* Which information do we have about the items? Bought / Seen / Rated / ... \n",
    "* From how many users do we have the info for a particular item \n",
    "* How old is that info? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: Non-Personalised Recommender using MovieLens Dataset\n",
    "We will work with the well known MovieLens dataset (http://grouplens.org/datasets/movielens/). This dataset was initially constructed to support participants in the Netflix Prize. Today, we can find several versions of this dataset with different amout of data, from 100k samples version to 20m sample version. Although performance on bigger dataset is expected to be better, we will work with the smallest dataset: MovieLens 100K Dataset (ml-100k-zip). Working with this lite version has the benefit of less computational costs\n",
    "\n",
    "With a unix machine the dataset can be downloaded with the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open ml-1m.zip, ml-1m.zip.zip or ml-1m.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip \n",
    "!unzip ml-1m.zip -d \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a windows machine, please go to the website and download the ml-1m version and extract it to the subdirectory named \"data/ml-1m/\"\n",
    "\n",
    "Once you have downloaded and unzipped the file into a directory, you can create a DataFrame with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 1000209 ratings\n",
      "La BD has  6040  users\n",
      "La BD has  3706  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                   title  movie_id  rating  \\\n",
       "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "\n",
       "  release_date  sex age  \n",
       "0        Drama    1   F  \n",
       "1        Drama   56   M  \n",
       "2        Drama   25   M  \n",
       "3        Drama   25   M  \n",
       "4        Drama   50   M  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the dataset in detail, you will see that it consists of:\n",
    "\n",
    "100,000 ratings from 943 users of 1682 movies. Ratings are from 1 to 5.\n",
    "Each user has rated at least 20 movies.\n",
    "Simple demographic info for the users (age, gender, occupation, zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Top movies ranking. \n",
    "The simplest way to show the ranking is by using the mean rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ulysses (Ulisse) (1954)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lured (1947)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Follow the Bitch (1998)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bittersweet Motel (2000)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Song of Freedom (1936)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Little Indian (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashing Time (1967)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schlafes Bruder (Brother of Sleep) (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gate of Heavenly Peace, The (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baby, The (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mean_rating\n",
       "title                                                 \n",
       "Ulysses (Ulisse) (1954)                            5.0\n",
       "Lured (1947)                                       5.0\n",
       "Follow the Bitch (1998)                            5.0\n",
       "Bittersweet Motel (2000)                           5.0\n",
       "Song of Freedom (1936)                             5.0\n",
       "One Little Indian (1973)                           5.0\n",
       "Smashing Time (1967)                               5.0\n",
       "Schlafes Bruder (Brother of Sleep) (1995)          5.0\n",
       "Gate of Heavenly Peace, The (1995)                 5.0\n",
       "Baby, The (1973)                                   5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score = data.groupby(['title'])[['rating']].mean().rename(columns = {'rating': 'mean_rating'})\n",
    "mean_score.sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "What do you think about the output? </div><br>\n",
    "Now, let's show only ranking the mean rating but using only those movies with at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "Any other idea?<br>\n",
    "How can you improve it?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Basic product association recommenders\n",
    "</h3><br> People who buy X also buy Y. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items 171\n",
      "Number of rows  9835\n",
      "An example: ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads']\n"
     ]
    }
   ],
   "source": [
    "#Let's read a dataset which contains several market baskets lists\n",
    "\n",
    "# read data/grocieries.csv\n",
    "def union(a, b):\n",
    "    \"\"\" return the union of two lists \"\"\"\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "market_data = []\n",
    "cont = 0\n",
    "items = []\n",
    "with open(\"data/groceries.csv\") as f:\n",
    "    for l in f:\n",
    "        market_data.append(l.rstrip().split(','))\n",
    "        items = union(items,l.rstrip().split(','))\n",
    "\n",
    "print(\"Number of different items\", len(items))\n",
    "print(\"Number of rows \", len(market_data))\n",
    "\n",
    "\n",
    "print(\"An example:\", market_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most simple ways to found association between product could be obtained as follows: $$score(Y|X) = \\frac{X \\ and \\ Y}{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the top associated product with \"yogurt\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products(product,N = 5):\n",
    "    d = {}\n",
    "    times = 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "\n",
    "    for k in d:\n",
    "        d[k] =   d[k] / times\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens? Is it a good measure? It has a problem with popular items...\n",
    "<br>\n",
    "Let's check this other formula:\n",
    "$$score(Y|X) = \\frac{ \\frac{X \\ and \\ Y}{X}} {  \\frac{!X \\ and \\ Y}{!X} }  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def top_associated_products2(product,N = 5):\n",
    "   \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products2('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products2('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products2('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check this last formula:\n",
    "$$ score(Y|X) = \\frac{P(X \\ and \\ Y)}{P(X)P(Y) }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products3(product,N = 5):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('baby food',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIORI Algorithm\n",
    "Typically, association rules are considered interesting if they satisfy both a minimum support threshold and a minimum confidence threshold\n",
    "\n",
    "![alt apriori](images/apriori.png)\n",
    "\n",
    "<b>Apriori principle</b>: Any subset of a frequent itemset must be frequent\n",
    "\n",
    "> Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "> -  A subset of a frequent itemset must also be a frequent itemset  i.e. if {1,2} is a frequent itemset, both {1} and {2} should be a frequent itemset\n",
    "> - Iteratively find frequent itemsets with cardinality from 1 to k (k-itemset)\n",
    "\n",
    "> Step 2: Use the frequent itemsets to generate association rules\n",
    "\n",
    "![alt apriori2](images/apriori2.png)\n",
    "\n",
    "Reference : \n",
    "[Fast algorithms for mining association rules](http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ngm/15-721/summaries/12.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted code from https://github.com/asaini/Apriori\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    \n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "    \n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    \n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in list(largeSet.items()):\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item)/getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                           confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key = lambda x: float(x[1])):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: float(x[1])):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'r')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('soda', 'whole milk') , 0.040\n",
      "item: ('white bread',) , 0.042\n",
      "item: ('tropical fruit', 'whole milk') , 0.042\n",
      "item: ('rolls/buns', 'other vegetables') , 0.043\n",
      "item: ('chicken',) , 0.043\n",
      "item: ('other vegetables', 'yogurt') , 0.043\n",
      "item: ('other vegetables', 'root vegetables') , 0.047\n",
      "item: ('frozen vegetables',) , 0.048\n",
      "item: ('whole milk', 'root vegetables') , 0.049\n",
      "item: ('chocolate',) , 0.050\n",
      "item: ('napkins',) , 0.052\n",
      "item: ('beef',) , 0.052\n",
      "item: ('curd',) , 0.053\n",
      "item: ('butter',) , 0.055\n",
      "item: ('whole milk', 'yogurt') , 0.056\n",
      "item: ('rolls/buns', 'whole milk') , 0.057\n",
      "item: ('pork',) , 0.058\n",
      "item: ('coffee',) , 0.058\n",
      "item: ('margarine',) , 0.059\n",
      "item: ('frankfurter',) , 0.059\n",
      "item: ('domestic eggs',) , 0.063\n",
      "item: ('brown bread',) , 0.065\n",
      "item: ('whipped/sour cream',) , 0.072\n",
      "item: ('fruit/vegetable juice',) , 0.072\n",
      "item: ('other vegetables', 'whole milk') , 0.075\n",
      "item: ('pip fruit',) , 0.076\n",
      "item: ('canned beer',) , 0.078\n",
      "item: ('newspapers',) , 0.080\n",
      "item: ('bottled beer',) , 0.081\n",
      "item: ('citrus fruit',) , 0.083\n",
      "item: ('pastry',) , 0.089\n",
      "item: ('sausage',) , 0.094\n",
      "item: ('shopping bags',) , 0.099\n",
      "item: ('tropical fruit',) , 0.105\n",
      "item: ('root vegetables',) , 0.109\n",
      "item: ('bottled water',) , 0.111\n",
      "item: ('yogurt',) , 0.140\n",
      "item: ('soda',) , 0.174\n",
      "item: ('rolls/buns',) , 0.184\n",
      "item: ('other vegetables',) , 0.193\n",
      "item: ('whole milk',) , 0.256\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('yogurt',) ==> ('whole milk',) , 0.402\n",
      "Rule: ('tropical fruit',) ==> ('whole milk',) , 0.403\n",
      "Rule: ('root vegetables',) ==> ('other vegetables',) , 0.435\n",
      "Rule: ('root vegetables',) ==> ('whole milk',) , 0.449\n"
     ]
    }
   ],
   "source": [
    "inFile = dataFromFile('data/groceries.csv')\n",
    "minSupport = 0.04\n",
    "minConfidence = 0.4\n",
    "items, rules =  runApriori(inFile, minSupport, minConfidence)\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice: Create and Product Association Recommender with MovieLens Dataset\n",
    "Explain the obtained results and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
