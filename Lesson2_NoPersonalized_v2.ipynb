{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated February 2019 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Non-Personalized recommeder systems</h3><br></div>\n",
    "\n",
    "<br>\n",
    "<p>A non-personalized recommender system is one that makes the same recommendations for everyone. </p>\n",
    "\n",
    "The simplest example is a retailer that shows the ten (or some number) most popular products on their homepage. <br>\n",
    "Some examples: <br><br>\n",
    "IMDB: MOVIE RANKING\n",
    "![alt IMDB](images/np1.png)\n",
    "\n",
    "___\n",
    "Amazon: Top Recommendations\n",
    "![alt Amazon](images/np2.png)\n",
    "___\n",
    "Amazon: Product Association\n",
    "![alt Amazon](images/np3.png)\n",
    "___\n",
    "Reedit: News Recommendations\n",
    "![alt Reedit](images/np4.png)\n",
    "\n",
    "\n",
    "<p><b>Several</b> cases but <b>two main</b> approaches\n",
    "\n",
    "1. Aggregated opinion recommenders\n",
    "2. Basic product association recommenders\n",
    "<br>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Aggregated opinion recommenders</h3><br></div>\n",
    "\n",
    "Usually, the problem posed as a learning to rank problem. But what seems to be straighfowrard becomes a really complicated question: <b>How do you rank your rated items and which logic to use to display them?</b>\n",
    "\n",
    "In order to score/rank items we first have to <b>understand the business case</b>. Of course, several factors plays a role. For instance, \n",
    "\n",
    "* Which information do we have about the items? Bought / Seen / Rated / ... \n",
    "* From how many users do we have the info for a particular item \n",
    "* How old is that info? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXAMPLE: Non-Personalised Recommender using MovieLens Dataset\n",
    "We will work with the well known MovieLens dataset (http://grouplens.org/datasets/movielens/). This dataset was initially constructed to support participants in the Netflix Prize. Today, we can find several versions of this dataset with different amout of data, from 100k samples version to 20m sample version. Although performance on bigger dataset is expected to be better, we will work with the smallest dataset: MovieLens 100K Dataset (ml-100k-zip). Working with this lite version has the benefit of less computational costs\n",
    "\n",
    "With a unix machine the dataset can be downloaded with the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\n",
      "unzip:  cannot find or open ml-1m.zip, ml-1m.zip.zip or ml-1m.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip \n",
    "!unzip ml-1m.zip -d \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a windows machine, please go to the website and download the 100k version and extract it to the subdirectory named \"data/ml-100k/\"\n",
    "\n",
    "Once you have downloaded and unzipped the file into a directory, you can create a DataFrame with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/Users/ssegui/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:19: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La BD has 1000209 ratings\n",
      "La BD has  6040  users\n",
      "La BD has  3706  movies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>56</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>Drama</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>Drama</td>\n",
       "      <td>50</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                   title  movie_id  rating  \\\n",
       "0        1  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "1        2  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "2       12  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "3       15  One Flew Over the Cuckoo's Nest (1975)      1193       4   \n",
       "4       17  One Flew Over the Cuckoo's Nest (1975)      1193       5   \n",
       "\n",
       "  release_date  sex age  \n",
       "0        Drama    1   F  \n",
       "1        Drama   56   M  \n",
       "2        Drama   25   M  \n",
       "3        Drama   25   M  \n",
       "4        Drama   50   M  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('data/ml-1m/users.dat', sep='::', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('data/ml-1m/ratings.dat', sep='::', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('data/ml-1m/movies.dat', sep='::', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the dataset in detail, you will see that it consists of:\n",
    "\n",
    "100,000 ratings from 943 users of 1682 movies. Ratings are from 1 to 5.\n",
    "Each user has rated at least 20 movies.\n",
    "Simple demographic info for the users (age, gender, occupation, zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Top movies ranking. \n",
    "The simplest way to show the ranking is by using the mean rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ulysses (Ulisse) (1954)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lured (1947)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Follow the Bitch (1998)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bittersweet Motel (2000)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Song of Freedom (1936)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One Little Indian (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashing Time (1967)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schlafes Bruder (Brother of Sleep) (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gate of Heavenly Peace, The (1995)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baby, The (1973)</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mean_rating\n",
       "title                                                 \n",
       "Ulysses (Ulisse) (1954)                            5.0\n",
       "Lured (1947)                                       5.0\n",
       "Follow the Bitch (1998)                            5.0\n",
       "Bittersweet Motel (2000)                           5.0\n",
       "Song of Freedom (1936)                             5.0\n",
       "One Little Indian (1973)                           5.0\n",
       "Smashing Time (1967)                               5.0\n",
       "Schlafes Bruder (Brother of Sleep) (1995)          5.0\n",
       "Gate of Heavenly Peace, The (1995)                 5.0\n",
       "Baby, The (1973)                                   5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score = data.groupby(['title'])[['rating']].mean().rename(columns = {'rating': 'mean_rating'})\n",
    "mean_score.sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "What do you think about the output? </div><br>\n",
    "Now, let's show only ranking the mean rating but using only those movies with at least 20 ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sanjuro (1962)</th>\n",
       "      <td>4.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)</th>\n",
       "      <td>4.560510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>4.554558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Godfather, The (1972)</th>\n",
       "      <td>4.524966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close Shave, A (1995)</th>\n",
       "      <td>4.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Usual Suspects, The (1995)</th>\n",
       "      <td>4.517106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schindler's List (1993)</th>\n",
       "      <td>4.510417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrong Trousers, The (1993)</th>\n",
       "      <td>4.507937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)</th>\n",
       "      <td>4.491489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raiders of the Lost Ark (1981)</th>\n",
       "      <td>4.477725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_rating\n",
       "title                                                          \n",
       "Sanjuro (1962)                                         4.608696\n",
       "Seven Samurai (The Magnificent Seven) (Shichini...     4.560510\n",
       "Shawshank Redemption, The (1994)                       4.554558\n",
       "Godfather, The (1972)                                  4.524966\n",
       "Close Shave, A (1995)                                  4.520548\n",
       "Usual Suspects, The (1995)                             4.517106\n",
       "Schindler's List (1993)                                4.510417\n",
       "Wrong Trousers, The (1993)                             4.507937\n",
       "Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)          4.491489\n",
       "Raiders of the Lost Ark (1981)                         4.477725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = data.groupby('title').size()\n",
    "mean_score.loc[size>20].sort_values(by='mean_rating',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "Any other idea?<br>\n",
    "How can you improve it?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is other measures like the <b>Damped Means</b>.\n",
    "\n",
    "\n",
    "* <b>Problem:</b> There is low conficende with few ratings\n",
    "* <b>Solution:</b> Assume that, without evidence, everything is average.\n",
    "\n",
    "<br>\n",
    "$damped\\_Means = \\frac{\\sum_u r_{u,i} + k \\mu}{n +  k}$\n",
    "<br><br>$k$ controls the strength of the requiered evidence\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>damped_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>318</td>\n",
       "      <td>4.550208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>Seven Samurai (The Magnificent Seven) (Shichin...</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.545166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "      <td>858</td>\n",
       "      <td>4.520741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>50</td>\n",
       "      <td>4.511888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>745</td>\n",
       "      <td>4.506470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  movie_id  damped_mean\n",
       "167                    Shawshank Redemption, The (1994)       318     4.550208\n",
       "1092  Seven Samurai (The Magnificent Seven) (Shichin...      2019     4.545166\n",
       "669                               Godfather, The (1972)       858     4.520741\n",
       "259                          Usual Suspects, The (1995)        50     4.511888\n",
       "29                                Close Shave, A (1995)       745     4.506470"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "mean_score_movies  = data.groupby('movie_id')[['rating']].mean().rename(columns = {'rating': 'mean_rating'}).reset_index()\n",
    "sum_ratings_movie = data.groupby('movie_id')[['rating']].sum().rename(columns = {'rating': 'num_ratings'}).reset_index()\n",
    "sum_ratings_movie['num_ratings_factor'] = sum_ratings_movie['num_ratings'] + k *(data['rating'].mean())\n",
    "\n",
    "count_ratings = data.groupby('movie_id')[['rating']].count().rename(columns = {'rating': 'count_rating'}).reset_index()\n",
    "count_ratings['count_rating_factor'] = count_ratings['count_rating'] + k\n",
    "\n",
    "ratings_damped = pd.merge(sum_ratings_movie,\n",
    "                         count_ratings[['movie_id','count_rating','count_rating_factor']],\n",
    "                         on=['movie_id'],how='left')\n",
    "\n",
    "ratings_damped['damped_mean']=ratings_damped['num_ratings_factor']/ratings_damped['count_rating_factor']\n",
    "\n",
    "ratings_mean_damped=pd.merge(data[['title','movie_id']].drop_duplicates(),\n",
    "                             ratings_damped[['movie_id','damped_mean']],\n",
    "                             on=['movie_id'],how='left')\n",
    "\n",
    "ratings_mean_damped = ratings_mean_damped.sort_values(by='damped_mean', ascending=False)\n",
    "ratings_mean_damped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ranking Cosiderations\n",
    "\n",
    "+ Confidence\n",
    " - How confident are we that this item is good?\n",
    " \n",
    "+ Risk tolerance\n",
    " - High-risk, high-reward\n",
    " - Conservative recommendations+\n",
    "\n",
    "+ Domain and business considerations\n",
    " - Age\n",
    " - System goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOTHER EXAMPLE DOMAIN CONSTRAINT: TIME\n",
    "\n",
    "<p><b>REDDIT:</b> Old stories are not interesting even though they might have a high net upvotes score! How does Reddit deal with this?</p>\n",
    "<br>\n",
    "$$log_{10}max( 1,| U -D | ) +  \\frac{sign(U-D)*t_{post}}{45000} $$ \n",
    "<br>\n",
    "where $U$ is the number of upvotes and $D$ is the number of downvotes. \n",
    "* In Reddit, time and votes were treated independently.\n",
    "* The Log term has a damping effect for votes. The idea is that votes 11 to 100 should have the same influence as votes 1 to 10. Obviously, a post with 1000 votes should be better than a post with 1 vote, but is a post with 2000 votes much better than the 1000 votes? The log decreases marginal values for later votes.\n",
    "* The sign(U-D) is useful to bury any negative items (as Reddit wants only to show the popular ones!)\n",
    "\n",
    "<p><b>HACKERS NEWS:</b> </p>\n",
    "\n",
    "$$ \\frac{(U - D  +1)^\\alpha}{(t_{now} - t_{post})^\\gamma} P $$\n",
    "\n",
    "* Numerator is related to popularity\n",
    "* Denominator is realted to the age factor with a gravity effect with the $\\gamma$ parameter\n",
    "* $P$ is a penalty term for each new\n",
    "\n",
    "![alt hackers](images/hackers.png)\n",
    "\n",
    "\n",
    "<h3>It was really famous and then it become to getting worse.</h3>\n",
    "![alt ![alt IMDB](images/zagat.png)\n",
    "](images/zagat.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Basic product association recommenders\n",
    "</h3><br> People who buy X also buy Y. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different items 171\n",
      "Number of rows  9835\n",
      "An example: ['pip fruit', 'yogurt', 'cream cheese ', 'meat spreads']\n"
     ]
    }
   ],
   "source": [
    "#Let's read a dataset which contains several market baskets lists\n",
    "\n",
    "# read data/grocieries.csv\n",
    "def union(a, b):\n",
    "    \"\"\" return the union of two lists \"\"\"\n",
    "    return list(set(a) | set(b))\n",
    "\n",
    "market_data = []\n",
    "cont = 0\n",
    "items = []\n",
    "with open(\"data/groceries.csv\") as f:\n",
    "    for l in f:\n",
    "        market_data.append(l.rstrip().split(','))\n",
    "        items = union(items,l.rstrip().split(','))\n",
    "\n",
    "print(\"Number of different items\", len(items))\n",
    "print(\"Number of rows \", len(market_data))\n",
    "\n",
    "\n",
    "print(\"An example:\", market_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most simple ways to found association between product could be obtained as follows: $$score(Y|X) = \\frac{X \\ and \\ Y}{X}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is the top associated product with \"yogurt\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products(product,N = 5):\n",
    "    d = {}\n",
    "    times = 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "\n",
    "    for k in d:\n",
    "        d[k] =   d[k] / times\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.40160349854227406), ('other vegetables', 0.3112244897959184), ('rolls/buns', 0.24635568513119532)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.6133333333333333), ('other vegetables', 0.52), ('root vegetables', 0.41333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('whole milk', 0.38636363636363635), ('other vegetables', 0.3409090909090909), ('tropical fruit', 0.20454545454545456)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens? Is it a good measure? It has a problem with popular items...\n",
    "<br>\n",
    "Let's check this other formula:\n",
    "$$score(Y|X) = \\frac{ \\frac{X \\ and \\ Y}{X}} {  \\frac{!X \\ and \\ Y}{!X} }  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def top_associated_products2(product,N = 5):\n",
    "    d, d_not, d_yes = {}, {}, {}\n",
    "    d = defaultdict(lambda: 0, d)\n",
    "    d_not = defaultdict(lambda: 0, d_not)\n",
    "    times, times_not = 0, 0\n",
    "    for l in market_data:\n",
    "        if product in l:\n",
    "            times = times + 1\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d_yes):\n",
    "                        d_yes[i] += 1.0\n",
    "                    else:\n",
    "                        d_yes[i] = 1.0\n",
    "        else:\n",
    "            times_not = times_not + 1\n",
    "            for i in l:\n",
    "                if(i in d_not):\n",
    "                    d_not[i] += 1.0\n",
    "                else:\n",
    "                    d_not[i] = 1.0\n",
    "                        \n",
    "    for k in d_yes:\n",
    "        if(d_not[k] == 0):\n",
    "            d[k] = 0\n",
    "        else:\n",
    "            d[k] =  ( d_yes[k] *times_not) / (times * d_not[k])\n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kitchen utensil', 6.168367346938775), ('preservation products', 6.168367346938775), ('meat spreads', 4.626275510204081)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products2('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('decalcifier', 20.02051282051282), ('canned fruit', 18.590476190476192), ('organic products', 18.590476190476192)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products2('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('artif. sweetener', 14.834848484848484), ('specialty vegetables', 13.907670454545455), ('cooking chocolate', 9.271780303030303)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rum\"?\n",
    "s = top_associated_products2('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check this last formula:\n",
    "$$ score(Y|X) = \\frac{P(X \\ and \\ Y)}{P(X)P(Y) }   $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_associated_products3(product,N = 5):\n",
    "    d , times = {}, {}\n",
    "    d = defaultdict(lambda: 0, d)\n",
    "    times = defaultdict(lambda: 0, times)\n",
    "    for l in market_data:\n",
    "        for item in l:\n",
    "            if item in times: #already exist\n",
    "                times[item] += 1\n",
    "            else:\n",
    "                times[item] =1\n",
    "        if product in l:\n",
    "            for i in l:\n",
    "                if i != product: \n",
    "                    if(i in d):\n",
    "                        d[i] += 1.0\n",
    "                    else:\n",
    "                        d[i] = 1.0\n",
    "                        \n",
    "    for k in d:\n",
    "        d[k] =  ( d[k] /len(market_data) ) / ((times[k]/len(market_data)) * times[product] /(len(market_data)))\n",
    "        \n",
    "    sorted_list=sorted(d.items(), key=lambda x: x[1],reverse=True)\n",
    "    return sorted_list[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('baby food', 7.168367346938775), ('kitchen utensil', 3.5841836734693877), ('preservation products', 3.5841836734693877)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('yogurt',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('decalcifier', 17.484444444444446), ('canned fruit', 16.391666666666666), ('organic products', 16.391666666666666)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rice',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('artif. sweetener', 13.970170454545455), ('specialty vegetables', 13.148395721925132), ('cooking chocolate', 8.940909090909091)]\n"
     ]
    }
   ],
   "source": [
    "# Which is the top associated prouct with \"rice\"?\n",
    "s = top_associated_products3('rum',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('finished products', 153.671875), ('soups', 146.7910447761194), ('cake bar', 75.65384615384615)]\n"
     ]
    }
   ],
   "source": [
    "s = top_associated_products3('baby food',N = 3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APRIORI Algorithm\n",
    "Typically, association rules are considered interesting if they satisfy both a minimum support threshold and a minimum confidence threshold\n",
    "\n",
    "![alt apriori](images/apriori.png)\n",
    "\n",
    "<b>Apriori principle</b>: Any subset of a frequent itemset must be frequent\n",
    "\n",
    "> Step 1: Find the frequent itemsset: the set of items that have minimum support.\n",
    "> -  A subset of a frequent itemset must also be a frequent itemset  i.e. if {1,2} is a frequent itemset, both {1} and {2} should be a frequent itemset\n",
    "> - Iteratively find frequent itemsets with cardinality from 1 to k (k-itemset)\n",
    "\n",
    "> Step 2: Use the frequent itemsets to generate association rules\n",
    "\n",
    "![alt apriori2](images/apriori2.png)\n",
    "\n",
    "Reference : \n",
    "[Fast algorithms for mining association rules](http://www-cgi.cs.cmu.edu/afs/cs.cmu.edu/Web/People/ngm/15-721/summaries/12.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted code from https://github.com/asaini/Apriori\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    \n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "    \n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    \n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in list(largeSet.items()):\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item)/getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                           confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key = lambda x: float(x[1])):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: float(x[1])):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'r')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: ('whole milk', 'soda') , 0.040\n",
      "item: ('white bread',) , 0.042\n",
      "item: ('whole milk', 'tropical fruit') , 0.042\n",
      "item: ('rolls/buns', 'other vegetables') , 0.043\n",
      "item: ('chicken',) , 0.043\n",
      "item: ('yogurt', 'other vegetables') , 0.043\n",
      "item: ('root vegetables', 'other vegetables') , 0.047\n",
      "item: ('frozen vegetables',) , 0.048\n",
      "item: ('root vegetables', 'whole milk') , 0.049\n",
      "item: ('chocolate',) , 0.050\n",
      "item: ('napkins',) , 0.052\n",
      "item: ('beef',) , 0.052\n",
      "item: ('curd',) , 0.053\n",
      "item: ('butter',) , 0.055\n",
      "item: ('yogurt', 'whole milk') , 0.056\n",
      "item: ('rolls/buns', 'whole milk') , 0.057\n",
      "item: ('pork',) , 0.058\n",
      "item: ('coffee',) , 0.058\n",
      "item: ('margarine',) , 0.059\n",
      "item: ('frankfurter',) , 0.059\n",
      "item: ('domestic eggs',) , 0.063\n",
      "item: ('brown bread',) , 0.065\n",
      "item: ('whipped/sour cream',) , 0.072\n",
      "item: ('fruit/vegetable juice',) , 0.072\n",
      "item: ('whole milk', 'other vegetables') , 0.075\n",
      "item: ('pip fruit',) , 0.076\n",
      "item: ('canned beer',) , 0.078\n",
      "item: ('newspapers',) , 0.080\n",
      "item: ('bottled beer',) , 0.081\n",
      "item: ('citrus fruit',) , 0.083\n",
      "item: ('pastry',) , 0.089\n",
      "item: ('sausage',) , 0.094\n",
      "item: ('shopping bags',) , 0.099\n",
      "item: ('tropical fruit',) , 0.105\n",
      "item: ('root vegetables',) , 0.109\n",
      "item: ('bottled water',) , 0.111\n",
      "item: ('yogurt',) , 0.140\n",
      "item: ('soda',) , 0.174\n",
      "item: ('rolls/buns',) , 0.184\n",
      "item: ('other vegetables',) , 0.193\n",
      "item: ('whole milk',) , 0.256\n",
      "\n",
      "------------------------ RULES:\n",
      "Rule: ('yogurt',) ==> ('whole milk',) , 0.402\n",
      "Rule: ('tropical fruit',) ==> ('whole milk',) , 0.403\n",
      "Rule: ('root vegetables',) ==> ('other vegetables',) , 0.435\n",
      "Rule: ('root vegetables',) ==> ('whole milk',) , 0.449\n"
     ]
    }
   ],
   "source": [
    "inFile = dataFromFile('data/groceries.csv')\n",
    "minSupport = 0.04\n",
    "minConfidence = 0.4\n",
    "items, rules =  runApriori(inFile, minSupport, minConfidence)\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice: Create and Product Association Recommender with MovieLens Dataset\n",
    "Explain the obtained results and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
